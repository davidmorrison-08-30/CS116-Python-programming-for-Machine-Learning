{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "mck4YxNXlTT3",
        "BZ-BnoYysjAi",
        "-aFJOv4Ls7SI",
        "3c-K3MlXALFO",
        "dViXleZl-Q2q",
        "XeFF4RKH-Lnt",
        "RzkiYTRq-18N",
        "eLSZnEflApNm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrXejhZwTtw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a755eb51-700f-4c01-a3a0-666800507242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "9rkkcYb9VJmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Final project/secondary_data_no_miss.csv', sep = \";\")"
      ],
      "metadata": {
        "id": "Pg4oomDSy1mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "yoqNj-9ky6wi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "e50463e4-7158-4431-ba29-7b0d9be79fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      class  cap-diameter cap-shape cap-surface cap-color  \\\n",
              "0         p         15.26         x           g         o   \n",
              "1         p         16.60         x           g         o   \n",
              "2         p         14.07         x           g         o   \n",
              "3         p         14.17         f           h         e   \n",
              "4         p         14.64         x           h         o   \n",
              "...     ...           ...       ...         ...       ...   \n",
              "61064     p          1.18         s           s         y   \n",
              "61065     p          1.27         f           s         y   \n",
              "61066     p          1.27         s           s         y   \n",
              "61067     p          1.24         f           s         y   \n",
              "61068     p          1.17         s           s         y   \n",
              "\n",
              "      does-bruise-or-bleed gill-attachment gill-spacing gill-color  \\\n",
              "0                        f               e          NaN          w   \n",
              "1                        f               e          NaN          w   \n",
              "2                        f               e          NaN          w   \n",
              "3                        f               e          NaN          w   \n",
              "4                        f               e          NaN          w   \n",
              "...                    ...             ...          ...        ...   \n",
              "61064                    f               f            f          f   \n",
              "61065                    f               f            f          f   \n",
              "61066                    f               f            f          f   \n",
              "61067                    f               f            f          f   \n",
              "61068                    f               f            f          f   \n",
              "\n",
              "       stem-height  ...  stem-root stem-surface stem-color veil-type  \\\n",
              "0            16.95  ...          s            y          w         u   \n",
              "1            17.99  ...          s            y          w         u   \n",
              "2            17.80  ...          s            y          w         u   \n",
              "3            15.77  ...          s            y          w         u   \n",
              "4            16.53  ...          s            y          w         u   \n",
              "...            ...  ...        ...          ...        ...       ...   \n",
              "61064         3.93  ...        NaN          NaN          y       NaN   \n",
              "61065         3.18  ...        NaN          NaN          y       NaN   \n",
              "61066         3.86  ...        NaN          NaN          y       NaN   \n",
              "61067         3.56  ...        NaN          NaN          y       NaN   \n",
              "61068         3.25  ...        NaN          NaN          y       NaN   \n",
              "\n",
              "      veil-color has-ring ring-type spore-print-color habitat season  \n",
              "0              w        t         g               NaN       d      w  \n",
              "1              w        t         g               NaN       d      u  \n",
              "2              w        t         g               NaN       d      w  \n",
              "3              w        t         p               NaN       d      w  \n",
              "4              w        t         p               NaN       d      w  \n",
              "...          ...      ...       ...               ...     ...    ...  \n",
              "61064        NaN        f         f               NaN       d      a  \n",
              "61065        NaN        f         f               NaN       d      a  \n",
              "61066        NaN        f         f               NaN       d      u  \n",
              "61067        NaN        f         f               NaN       d      u  \n",
              "61068        NaN        f         f               NaN       d      u  \n",
              "\n",
              "[61069 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3248bb89-3208-401c-b2c0-e4a964f897c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-diameter</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>does-bruise-or-bleed</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stem-height</th>\n",
              "      <th>...</th>\n",
              "      <th>stem-root</th>\n",
              "      <th>stem-surface</th>\n",
              "      <th>stem-color</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>has-ring</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>habitat</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>15.26</td>\n",
              "      <td>x</td>\n",
              "      <td>g</td>\n",
              "      <td>o</td>\n",
              "      <td>f</td>\n",
              "      <td>e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>w</td>\n",
              "      <td>16.95</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>u</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p</td>\n",
              "      <td>16.60</td>\n",
              "      <td>x</td>\n",
              "      <td>g</td>\n",
              "      <td>o</td>\n",
              "      <td>f</td>\n",
              "      <td>e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>w</td>\n",
              "      <td>17.99</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>u</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p</td>\n",
              "      <td>14.07</td>\n",
              "      <td>x</td>\n",
              "      <td>g</td>\n",
              "      <td>o</td>\n",
              "      <td>f</td>\n",
              "      <td>e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>w</td>\n",
              "      <td>17.80</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>u</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>14.17</td>\n",
              "      <td>f</td>\n",
              "      <td>h</td>\n",
              "      <td>e</td>\n",
              "      <td>f</td>\n",
              "      <td>e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>w</td>\n",
              "      <td>15.77</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>u</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p</td>\n",
              "      <td>14.64</td>\n",
              "      <td>x</td>\n",
              "      <td>h</td>\n",
              "      <td>o</td>\n",
              "      <td>f</td>\n",
              "      <td>e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>w</td>\n",
              "      <td>16.53</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>u</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61064</th>\n",
              "      <td>p</td>\n",
              "      <td>1.18</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>3.93</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61065</th>\n",
              "      <td>p</td>\n",
              "      <td>1.27</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>3.18</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61066</th>\n",
              "      <td>p</td>\n",
              "      <td>1.27</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>3.86</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61067</th>\n",
              "      <td>p</td>\n",
              "      <td>1.24</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>3.56</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61068</th>\n",
              "      <td>p</td>\n",
              "      <td>1.17</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>3.25</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61069 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3248bb89-3208-401c-b2c0-e4a964f897c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3248bb89-3208-401c-b2c0-e4a964f897c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3248bb89-3208-401c-b2c0-e4a964f897c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "jrBIMr2Ny7_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ee686e-4dfa-4c28-94c0-a912e04c5217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 61069 entries, 0 to 61068\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   class                 61069 non-null  object \n",
            " 1   cap-diameter          61069 non-null  float64\n",
            " 2   cap-shape             61069 non-null  object \n",
            " 3   cap-surface           46949 non-null  object \n",
            " 4   cap-color             61069 non-null  object \n",
            " 5   does-bruise-or-bleed  61069 non-null  object \n",
            " 6   gill-attachment       51185 non-null  object \n",
            " 7   gill-spacing          36006 non-null  object \n",
            " 8   gill-color            61069 non-null  object \n",
            " 9   stem-height           61069 non-null  float64\n",
            " 10  stem-width            61069 non-null  float64\n",
            " 11  stem-root             9531 non-null   object \n",
            " 12  stem-surface          22945 non-null  object \n",
            " 13  stem-color            61069 non-null  object \n",
            " 14  veil-type             3177 non-null   object \n",
            " 15  veil-color            7413 non-null   object \n",
            " 16  has-ring              61069 non-null  object \n",
            " 17  ring-type             58598 non-null  object \n",
            " 18  spore-print-color     6354 non-null   object \n",
            " 19  habitat               61069 non-null  object \n",
            " 20  season                61069 non-null  object \n",
            "dtypes: float64(3), object(18)\n",
            "memory usage: 9.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "0sse3DjdzMju",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "16473a40-4da9-487e-eba6-a56e61215862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       cap-diameter   stem-height    stem-width\n",
              "count  61069.000000  61069.000000  61069.000000\n",
              "mean       6.733854      6.581538     12.149410\n",
              "std        5.264845      3.370017     10.035955\n",
              "min        0.380000      0.000000      0.000000\n",
              "25%        3.480000      4.640000      5.210000\n",
              "50%        5.860000      5.950000     10.190000\n",
              "75%        8.540000      7.740000     16.570000\n",
              "max       62.340000     33.920000    103.910000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d14b3ba9-f0eb-46cc-8940-9bbcc38e0b32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-diameter</th>\n",
              "      <th>stem-height</th>\n",
              "      <th>stem-width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>61069.000000</td>\n",
              "      <td>61069.000000</td>\n",
              "      <td>61069.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.733854</td>\n",
              "      <td>6.581538</td>\n",
              "      <td>12.149410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.264845</td>\n",
              "      <td>3.370017</td>\n",
              "      <td>10.035955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.480000</td>\n",
              "      <td>4.640000</td>\n",
              "      <td>5.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.860000</td>\n",
              "      <td>5.950000</td>\n",
              "      <td>10.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.540000</td>\n",
              "      <td>7.740000</td>\n",
              "      <td>16.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>62.340000</td>\n",
              "      <td>33.920000</td>\n",
              "      <td>103.910000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d14b3ba9-f0eb-46cc-8940-9bbcc38e0b32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d14b3ba9-f0eb-46cc-8940-9bbcc38e0b32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d14b3ba9-f0eb-46cc-8940-9bbcc38e0b32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['class'].replace({'p':0,'e':1},inplace = True)"
      ],
      "metadata": {
        "id": "ImzkE2WFS9vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mck4YxNXlTT3"
      },
      "source": [
        "# **EXPLORATORY DATA ANALYSIS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ-BnoYysjAi"
      },
      "source": [
        "## COUNTING VALUES IN EACH COLUMN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UsTNfEPO5dej",
        "outputId": "c39b19cb-11e2-4e73-bd99-f8d6c28d3a2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "rindex, colindex = 0, 0\n",
        "for col in df.columns:\n",
        "  if rindex == 0 and colindex == 0:\n",
        "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
        "  countings = df.groupby(col).apply(len)\n",
        "  countings = pd.DataFrame(countings)\n",
        "  countings.reset_index(inplace=True)\n",
        "  countings.columns=[col, \"count\"]\n",
        "  axes[rindex, colindex].bar(countings[col], countings[\"count\"], color=\"red\")\n",
        "  axes[rindex, colindex].title.set_text(col)\n",
        "  if colindex == 2:\n",
        "    rindex += 1\n",
        "    colindex = 0\n",
        "  else: colindex += 1\n",
        "  if rindex == 3 or col == \"habitat\":\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    rindex, colindex = 0, 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aFJOv4Ls7SI"
      },
      "source": [
        "## DISTRIBUTION OF EDIBLE AND POISONOUS MUSHROOMS OVER VARIOUS FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "k6Kltyk5BH1V",
        "outputId": "8152038f-54eb-4b57-d068-2ebd09441823"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "rindex, colindex = 0, 0\n",
        "for col in [\"gill-spacing\", \"gill-color\"]:\n",
        "  if rindex == 0 and colindex == 0:\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
        "  sns.countplot(ax = axes[rindex, colindex], data=df, x=col, hue=\"class\")\n",
        "  axes[rindex, colindex].title.set_text(col)\n",
        "  # if colindex == 1:\n",
        "  #   rindex += 1\n",
        "  #   colindex = 0\n",
        "\n",
        "  colindex += 1\n",
        "  if colindex == 2:\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    rindex, colindex = 0, 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "sns.countplot(ax = ax1, data=df, x=\"gill-attachment\", hue=\"class\")\n",
        "# ax1.title.set_text(\"gill-spacing\")\n",
        "sns.countplot(ax = ax2, data=df, x=\"stem-color\", hue=\"class\")\n",
        "# ax1.title.set_text(\"gill-color\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "eZFR1CJ0uPOy",
        "outputId": "f8134be1-6eec-4aeb-ff1e-f152015a4a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data=df, x=\"stem-width\", y=\"stem-height\", hue=\"class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "TRjX-b8c0BA4",
        "outputId": "9f0336cd-d2e2-4dd1-8897-49e162e6b71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data=df, x=\"stem-height\", y=\"cap-diameter\", hue=\"class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "LoKcollq4iKR",
        "outputId": "ea10a973-73a2-4b4d-bd19-96bd39272838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "mLlDmascX-Gk",
        "outputId": "a7b0a11f-0beb-4361-df05-6c70b0826a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-9c81afdf135e>:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  sns.heatmap(df.corr(), annot=True, fmt=\".2f\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Correlation Between Features')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(df.corr(), annot=True, fmt=\".2f\")\n",
        "plt.title(\"Correlation Between Features\", fontsize=18, color=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "3c-K3MlXALFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LE = LabelEncoder()\n",
        "for col in data.drop([\"cap-diameter\",\"stem-height\",\"stem-width\",\"class\"],axis=1).columns:\n",
        "    data[col] = LE.fit_transform(data[col])\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "NjlTAOLTzP7j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "b6b5ebfa-b156-493a-ba33-3f6de5c1c1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class  cap-diameter  cap-shape  cap-surface  cap-color  \\\n",
              "0          0         15.26          6            2          6   \n",
              "1          0         16.60          6            2          6   \n",
              "2          0         14.07          6            2          6   \n",
              "3          0         14.17          2            3          1   \n",
              "4          0         14.64          6            3          6   \n",
              "...      ...           ...        ...          ...        ...   \n",
              "61064      0          1.18          5            7         11   \n",
              "61065      0          1.27          2            7         11   \n",
              "61066      0          1.27          5            7         11   \n",
              "61067      0          1.24          2            7         11   \n",
              "61068      0          1.17          5            7         11   \n",
              "\n",
              "       does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
              "0                         0                2             3          10   \n",
              "1                         0                2             3          10   \n",
              "2                         0                2             3          10   \n",
              "3                         0                2             3          10   \n",
              "4                         0                2             3          10   \n",
              "...                     ...              ...           ...         ...   \n",
              "61064                     0                3             2           2   \n",
              "61065                     0                3             2           2   \n",
              "61066                     0                3             2           2   \n",
              "61067                     0                3             2           2   \n",
              "61068                     0                3             2           2   \n",
              "\n",
              "       stem-height  ...  stem-root  stem-surface  stem-color  veil-type  \\\n",
              "0            16.95  ...          4             7          11          0   \n",
              "1            17.99  ...          4             7          11          0   \n",
              "2            17.80  ...          4             7          11          0   \n",
              "3            15.77  ...          4             7          11          0   \n",
              "4            16.53  ...          4             7          11          0   \n",
              "...            ...  ...        ...           ...         ...        ...   \n",
              "61064         3.93  ...          5             8          12          1   \n",
              "61065         3.18  ...          5             8          12          1   \n",
              "61066         3.86  ...          5             8          12          1   \n",
              "61067         3.56  ...          5             8          12          1   \n",
              "61068         3.25  ...          5             8          12          1   \n",
              "\n",
              "       veil-color  has-ring  ring-type  spore-print-color  habitat  season  \n",
              "0               4         1          2                  7        0       3  \n",
              "1               4         1          2                  7        0       2  \n",
              "2               4         1          2                  7        0       3  \n",
              "3               4         1          5                  7        0       3  \n",
              "4               4         1          5                  7        0       3  \n",
              "...           ...       ...        ...                ...      ...     ...  \n",
              "61064           6         0          1                  7        0       0  \n",
              "61065           6         0          1                  7        0       0  \n",
              "61066           6         0          1                  7        0       2  \n",
              "61067           6         0          1                  7        0       2  \n",
              "61068           6         0          1                  7        0       2  \n",
              "\n",
              "[61069 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dc36b29-7a63-41c7-9671-29fb44637c08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-diameter</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>does-bruise-or-bleed</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stem-height</th>\n",
              "      <th>...</th>\n",
              "      <th>stem-root</th>\n",
              "      <th>stem-surface</th>\n",
              "      <th>stem-color</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>has-ring</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>habitat</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15.26</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>16.95</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>16.60</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>17.99</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>14.07</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>17.80</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14.17</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>15.77</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>14.64</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>16.53</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61064</th>\n",
              "      <td>0</td>\n",
              "      <td>1.18</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3.93</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61065</th>\n",
              "      <td>0</td>\n",
              "      <td>1.27</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3.18</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61066</th>\n",
              "      <td>0</td>\n",
              "      <td>1.27</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3.86</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61067</th>\n",
              "      <td>0</td>\n",
              "      <td>1.24</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3.56</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61068</th>\n",
              "      <td>0</td>\n",
              "      <td>1.17</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3.25</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61069 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dc36b29-7a63-41c7-9671-29fb44637c08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dc36b29-7a63-41c7-9671-29fb44637c08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dc36b29-7a63-41c7-9671-29fb44637c08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in [\"cap-diameter\",\"stem-height\",\"stem-width\"]:\n",
        "  standard_scaler = StandardScaler()\n",
        "  data[col] = standard_scaler.fit_transform(data.loc[:,[col]])"
      ],
      "metadata": {
        "id": "e9BaZEGzO8lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "omceBnFPPY7y",
        "outputId": "75798162-484c-4eb1-ff07-0d1bae594a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class  cap-diameter  cap-shape  cap-surface  cap-color  \\\n",
              "0          0      1.619462          6            2          6   \n",
              "1          0      1.873982          6            2          6   \n",
              "2          0      1.393432          6            2          6   \n",
              "3          0      1.412426          2            3          1   \n",
              "4          0      1.501699          6            3          6   \n",
              "...      ...           ...        ...          ...        ...   \n",
              "61064      0     -1.054903          5            7         11   \n",
              "61065      0     -1.037808          2            7         11   \n",
              "61066      0     -1.037808          5            7         11   \n",
              "61067      0     -1.043506          2            7         11   \n",
              "61068      0     -1.056802          5            7         11   \n",
              "\n",
              "       does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
              "0                         0                2             3          10   \n",
              "1                         0                2             3          10   \n",
              "2                         0                2             3          10   \n",
              "3                         0                2             3          10   \n",
              "4                         0                2             3          10   \n",
              "...                     ...              ...           ...         ...   \n",
              "61064                     0                3             2           2   \n",
              "61065                     0                3             2           2   \n",
              "61066                     0                3             2           2   \n",
              "61067                     0                3             2           2   \n",
              "61068                     0                3             2           2   \n",
              "\n",
              "       stem-height  ...  stem-root  stem-surface  stem-color  veil-type  \\\n",
              "0         3.076705  ...          4             7          11          0   \n",
              "1         3.385311  ...          4             7          11          0   \n",
              "2         3.328931  ...          4             7          11          0   \n",
              "3         2.726555  ...          4             7          11          0   \n",
              "4         2.952075  ...          4             7          11          0   \n",
              "...            ...  ...        ...           ...         ...        ...   \n",
              "61064    -0.786809  ...          5             8          12          1   \n",
              "61065    -1.009362  ...          5             8          12          1   \n",
              "61066    -0.807581  ...          5             8          12          1   \n",
              "61067    -0.896602  ...          5             8          12          1   \n",
              "61068    -0.988590  ...          5             8          12          1   \n",
              "\n",
              "       veil-color  has-ring  ring-type  spore-print-color  habitat  season  \n",
              "0               4         1          2                  7        0       3  \n",
              "1               4         1          2                  7        0       2  \n",
              "2               4         1          2                  7        0       3  \n",
              "3               4         1          5                  7        0       3  \n",
              "4               4         1          5                  7        0       3  \n",
              "...           ...       ...        ...                ...      ...     ...  \n",
              "61064           6         0          1                  7        0       0  \n",
              "61065           6         0          1                  7        0       0  \n",
              "61066           6         0          1                  7        0       2  \n",
              "61067           6         0          1                  7        0       2  \n",
              "61068           6         0          1                  7        0       2  \n",
              "\n",
              "[61069 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37f60050-4f34-4b41-b7cb-08923da01590\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-diameter</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>does-bruise-or-bleed</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stem-height</th>\n",
              "      <th>...</th>\n",
              "      <th>stem-root</th>\n",
              "      <th>stem-surface</th>\n",
              "      <th>stem-color</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>has-ring</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>habitat</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.619462</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3.076705</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.873982</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3.385311</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1.393432</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3.328931</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1.412426</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2.726555</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1.501699</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2.952075</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61064</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.054903</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.786809</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61065</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.037808</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.009362</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61066</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.037808</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.807581</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61067</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.043506</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.896602</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61068</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.056802</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.988590</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61069 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37f60050-4f34-4b41-b7cb-08923da01590')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37f60050-4f34-4b41-b7cb-08923da01590 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37f60050-4f34-4b41-b7cb-08923da01590');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data[\"class\"]"
      ],
      "metadata": {
        "id": "u7sxbhsbz24p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop([\"class\"], axis=1)"
      ],
      "metadata": {
        "id": "SKcMMNl6PmdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "X_train"
      ],
      "metadata": {
        "id": "AUTlZdKC17qW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "972939c3-fb2d-4077-b3c7-4cb74c1bd8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       cap-diameter  cap-shape  cap-surface  cap-color  does-bruise-or-bleed  \\\n",
              "11067     -0.872560          6            2          1                     0   \n",
              "48406      2.776201          6            9          5                     0   \n",
              "38752      0.637469          6           11          5                     1   \n",
              "3449       1.302261          6           10          5                     1   \n",
              "14139     -0.091904          6            3          2                     0   \n",
              "...             ...        ...          ...        ...                   ...   \n",
              "60620     -0.395809          4           11          5                     0   \n",
              "56373      0.263285          3            5          6                     0   \n",
              "34086      0.052451          6            9          7                     0   \n",
              "58067     -0.680720          3            6          2                     0   \n",
              "27439      2.092414          5            5         10                     1   \n",
              "\n",
              "       gill-attachment  gill-spacing  gill-color  stem-height  stem-width  \\\n",
              "11067                0             3           7    -0.341704   -0.998360   \n",
              "48406                4             3          11     3.978785    7.171333   \n",
              "38752                6             3           9     0.833374    0.944670   \n",
              "3449                 2             3          10     0.854146    0.408593   \n",
              "14139                0             1           5    -0.190368   -0.741282   \n",
              "...                ...           ...         ...          ...         ...   \n",
              "60620                3             2           2    -0.567224    0.722467   \n",
              "56373                7             0          11    -1.436663    0.374715   \n",
              "34086                5             0           7    -0.614702   -0.309830   \n",
              "58067                3             2           2    -1.952985   -1.210598   \n",
              "27439                1             1           5     0.067793    1.888285   \n",
              "\n",
              "       stem-root  stem-surface  stem-color  veil-type  veil-color  has-ring  \\\n",
              "11067          5             8          11          1           6         0   \n",
              "48406          5             8           6          1           6         0   \n",
              "38752          4             8           6          1           3         0   \n",
              "3449           5             8          11          1           6         1   \n",
              "14139          5             6           3          1           6         1   \n",
              "...          ...           ...         ...        ...         ...       ...   \n",
              "60620          5             8           6          1           6         0   \n",
              "56373          5             8           6          1           6         0   \n",
              "34086          5             8           8          1           6         0   \n",
              "58067          2             0           2          1           6         0   \n",
              "27439          5             8          11          1           6         0   \n",
              "\n",
              "       ring-type  spore-print-color  habitat  season  \n",
              "11067          1                  7        0       2  \n",
              "48406          1                  7        0       2  \n",
              "38752          1                  7        0       0  \n",
              "3449           8                  7        0       0  \n",
              "14139          3                  7        0       0  \n",
              "...          ...                ...      ...     ...  \n",
              "60620          1                  7        3       1  \n",
              "56373          1                  7        0       3  \n",
              "34086          1                  7        0       0  \n",
              "58067          1                  7        0       2  \n",
              "27439          1                  7        0       0  \n",
              "\n",
              "[48855 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6b56405-a735-4ee4-bf67-b07c1a99cdeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-diameter</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>does-bruise-or-bleed</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stem-height</th>\n",
              "      <th>stem-width</th>\n",
              "      <th>stem-root</th>\n",
              "      <th>stem-surface</th>\n",
              "      <th>stem-color</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>has-ring</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>habitat</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11067</th>\n",
              "      <td>-0.872560</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.341704</td>\n",
              "      <td>-0.998360</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48406</th>\n",
              "      <td>2.776201</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>3.978785</td>\n",
              "      <td>7.171333</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38752</th>\n",
              "      <td>0.637469</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0.833374</td>\n",
              "      <td>0.944670</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3449</th>\n",
              "      <td>1.302261</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>0.854146</td>\n",
              "      <td>0.408593</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14139</th>\n",
              "      <td>-0.091904</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.190368</td>\n",
              "      <td>-0.741282</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60620</th>\n",
              "      <td>-0.395809</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.567224</td>\n",
              "      <td>0.722467</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56373</th>\n",
              "      <td>0.263285</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>-1.436663</td>\n",
              "      <td>0.374715</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34086</th>\n",
              "      <td>0.052451</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.614702</td>\n",
              "      <td>-0.309830</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58067</th>\n",
              "      <td>-0.680720</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.952985</td>\n",
              "      <td>-1.210598</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27439</th>\n",
              "      <td>2.092414</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.067793</td>\n",
              "      <td>1.888285</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48855 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6b56405-a735-4ee4-bf67-b07c1a99cdeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6b56405-a735-4ee4-bf67-b07c1a99cdeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6b56405-a735-4ee4-bf67-b07c1a99cdeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "BmgYiu6g1_ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e5b080-01ac-49e0-e89b-9d87dd01d3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11067    0\n",
              "48406    1\n",
              "38752    0\n",
              "3449     1\n",
              "14139    1\n",
              "        ..\n",
              "60620    1\n",
              "56373    0\n",
              "34086    0\n",
              "58067    0\n",
              "27439    0\n",
              "Name: class, Length: 48855, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SUPPORT VECTOR MACHINES**"
      ],
      "metadata": {
        "id": "dViXleZl-Q2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "U-cIceGk2IT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fRVgDFHk2JVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3dbe3d95-d22b-4b7a-a4e2-4eca673eaebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ZDSgCY-l2LOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment"
      ],
      "metadata": {
        "id": "ieOpshl-PrrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "oRF1kgQu2NrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48cf047f-5e23-45a3-dc33-4ed951210cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6600622236777468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)"
      ],
      "metadata": {
        "id": "BVCqKYBN2QDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e458b7-9a9e-4613-8ae9-68863c9b96f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[5202 1599]\n",
            " [2553 2860]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "print(\"Precision:\", precision)"
      ],
      "metadata": {
        "id": "8TipPsHf37Q8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bab32b-d2de-4b20-c1df-bdb0225d87dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.641399416909621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall = recall_score(y_test, y_pred, pos_label=1)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "lzlt0HDr37rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b307fc59-550d-4f75-bd36-91ea00953341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.5283576574912249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "gv8QfbMY4KQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b45e43-ae4a-4971-9b81-bd9b149fc862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.5794165316045381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "B5eKdUoMSj4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "}"
      ],
      "metadata": {
        "id": "b5oJlWVPTR77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "9SvevkvBV7ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(svm, param_grid, cv=2)"
      ],
      "metadata": {
        "id": "ck-EYeC-Vegv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "2HE68tM0VqEc",
        "outputId": "82c3cafd-fd68-47b2-e1d8-157c0445b620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=SVC(kernel='linear'),\n",
              "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
              "                         'kernel': ['linear', 'rbf']})"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(\"Siêu tham số tốt nhất:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7VQruaSVvBv",
        "outputId": "853b7192-91c1-4d12-94e8-759127757352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Siêu tham số tốt nhất: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_search.predict(X_test)"
      ],
      "metadata": {
        "id": "6_KozuGr48d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(f\"Accuracy score after using GridSearchCV is: {accuracy_score(y_test,y_pred)}\")\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJETlEfm5U5R",
        "outputId": "3880ec32-758a-4ae1-848f-8b127a6671da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score after using GridSearchCV is: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6801\n",
            "           1       1.00      1.00      1.00      5413\n",
            "\n",
            "    accuracy                           1.00     12214\n",
            "   macro avg       1.00      1.00      1.00     12214\n",
            "weighted avg       1.00      1.00      1.00     12214\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K NEAREST NEIGHBORS**"
      ],
      "metadata": {
        "id": "XeFF4RKH-Lnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score"
      ],
      "metadata": {
        "id": "9oWpgI36_Dqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53a7949a",
        "outputId": "2bd81875-eac4-407f-a2cf-c5cc44e10c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6748   16]\n",
            " [  20 5430]]\n",
            "Accuracy score using Random Forest is: 0.9970525626330441\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6764\n",
            "           1       1.00      1.00      1.00      5450\n",
            "\n",
            "    accuracy                           1.00     12214\n",
            "   macro avg       1.00      1.00      1.00     12214\n",
            "weighted avg       1.00      1.00      1.00     12214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(f\"Accuracy score using Random Forest is: {accuracy_score(y_test,y_pred)}\")\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9535d91"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf46d293"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dd32d6a"
      },
      "outputs": [],
      "source": [
        "operations = [('scaler', scaler), ('knn', knn)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb86d6e4"
      },
      "outputs": [],
      "source": [
        "k_values = list(range(1,30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc005aa2"
      },
      "outputs": [],
      "source": [
        "param_grid = {'knn__n_neighbors': k_values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0087670"
      },
      "outputs": [],
      "source": [
        "full_cv_classifier = GridSearchCV(pipe, param_grid, cv=5, scoring = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15a25e68",
        "outputId": "5ea68a7f-f036-44e0-df88-39e968368561"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;knn&#x27;, KNeighborsClassifier())]),\n",
              "             param_grid={&#x27;knn__n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                              12, 13, 14, 15, 16, 17, 18, 19,\n",
              "                                              20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                              28, 29]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;knn&#x27;, KNeighborsClassifier())]),\n",
              "             param_grid={&#x27;knn__n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                              12, 13, 14, 15, 16, 17, 18, 19,\n",
              "                                              20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                              28, 29]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;knn&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                       ('knn', KNeighborsClassifier())]),\n",
              "             param_grid={'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                              12, 13, 14, 15, 16, 17, 18, 19,\n",
              "                                              20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                              28, 29]},\n",
              "             scoring='accuracy')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_cv_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2169bf47",
        "outputId": "736b800b-3cd3-48e8-80d2-6aa30e062dbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.99969297, 0.99930406, 0.99899703, 0.99877188, 0.99823969,\n",
              "       0.99776891, 0.99740047, 0.99676594, 0.99621328, 0.99584485,\n",
              "       0.99539453, 0.9950261 , 0.99402313, 0.99357282, 0.99277454,\n",
              "       0.99244704, 0.99183298, 0.99148501, 0.99083001, 0.99035923,\n",
              "       0.98976563, 0.98919251, 0.9884761 , 0.98757548, 0.98628595,\n",
              "       0.98548767, 0.98462798, 0.98413673, 0.98278579])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_cv_classifier.cv_results_['mean_test_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5810638",
        "outputId": "4fbd844f-596a-4d02-c5d9-b6b56b9bfec0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('knn', KNeighborsClassifier(n_neighbors=1))])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = full_cv_classifier.best_estimator_\n",
        "full_cv_classifier.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a114c368",
        "outputId": "5f70e047-cf81-4b00-c4d2-3c8b7c5b9cab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x1cd66197160>]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(k_values, full_cv_classifier.cv_results_['mean_test_score'],\"-o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "840cbd31",
        "outputId": "0a0e24a4-bda6-42f3-9dc8-6b8abbde5687"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('knn', KNeighborsClassifier(n_neighbors=1))])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89a63d0a"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d9cafab",
        "outputId": "ef07c713-86fe-4ab7-ac3e-cbb02e19a073"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[6764,    0],\n",
              "       [   3, 5447]], dtype=int64)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8daca70",
        "outputId": "3e89427c-7506-4e0d-9359-36eb43b6aca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score using Random Forest is: 0.9997543802194203\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6764\n",
            "           1       1.00      1.00      1.00      5450\n",
            "\n",
            "    accuracy                           1.00     12214\n",
            "   macro avg       1.00      1.00      1.00     12214\n",
            "weighted avg       1.00      1.00      1.00     12214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy score using Random Forest is: {accuracy_score(y_test,y_pred)}\")\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DECISION TREE**"
      ],
      "metadata": {
        "id": "RzkiYTRq-18N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time"
      ],
      "metadata": {
        "id": "BzVz3fip-4lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAw-DzBX_IHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ71TaEVOoRZ"
      },
      "source": [
        "## Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mil6U5iN2Ee"
      },
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hzZfmgDOP0B"
      },
      "outputs": [],
      "source": [
        "# scaler = StandardScaler()\n",
        "# operations = [('scaler', scaler), ('dt', dt_model)]\n",
        "# pipe = Pipeline(operations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "uw3LHR3BOHsE",
        "outputId": "c2c34152-0de9-4d74-9c8c-d9bfc754ebee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dt_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl0UZom0MHsn",
        "outputId": "2a5175d5-4e07-41ce-e86c-362ac37cc39f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9963975765514983\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.997     0.997     0.997      6774\n",
            "           1      0.996     0.996     0.996      5440\n",
            "\n",
            "    accuracy                          0.996     12214\n",
            "   macro avg      0.996     0.996     0.996     12214\n",
            "weighted avg      0.996     0.996     0.996     12214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = dt_model.predict(X_test)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAB9xVbvIyqq",
        "outputId": "413d5481-84d1-4e38-931a-c736f174d7e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree's accuracy:  0.9963975765514983\n",
            "Decision Tree's precision:  0.9959558823529412\n",
            "Decision Tree's recall:  0.9959558823529412\n",
            "Decision Tree's F1 score:  0.9959558823529412\n",
            "Decision Tree's roc_auc score:  0.9963540852567777\n"
          ]
        }
      ],
      "source": [
        "print(\"Decision Tree's accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"Decision Tree's precision: \", precision_score(y_test, y_pred))\n",
        "print(\"Decision Tree's recall: \", recall_score(y_test, y_pred))\n",
        "print(\"Decision Tree's F1 score: \", f1_score(y_test, y_pred))\n",
        "print(\"Decision Tree's roc_auc score: \", roc_auc_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKVNjp_w90Pv"
      },
      "source": [
        "## Grid Search Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYJNdcbJ90Pw"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgoSfabA90Pw"
      },
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T41sFPQwQI4Z"
      },
      "outputs": [],
      "source": [
        "# scaler = StandardScaler()\n",
        "# operations = [('scaler', scaler), ('dt', dt_model)]\n",
        "# pipe = Pipeline(operations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJJpAGXyPXlM"
      },
      "outputs": [],
      "source": [
        "param_grid_2 = {'max_depth': [None] + list(np.arange(3,10)),\n",
        "              'min_samples_split': np.arange(2, 10, 1),\n",
        "              'min_samples_leaf':np.arange(1, 10, 1),\n",
        "              'max_leaf_nodes' : [None, 8, 16, 32],\n",
        "              'criterion': ('gini', 'entropy', 'log_loss'),\n",
        "              # 'ccp_alpha': [0, 0.1, .01, .001]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW0N9C_x90Pw",
        "outputId": "fd5e0897-650c-45b8-aa37-e070fad2610b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.806, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.743, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.743, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.743, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.743, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.743, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.743, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.806, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.743, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.806, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.743, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.806, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.743, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.806, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.730, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.730, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.806, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.730, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.730, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.730, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.730, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.730, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.730, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.806, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.806, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.806, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.806, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.806, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.806, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.806, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.806, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.806, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.805, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.805, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.805, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.805, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.805, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.805, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.805, test=0.812) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.805, test=0.812) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.805, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.805, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.805, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.805, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.742, test=0.738) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.751, test=0.757) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.729, test=0.729) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.805, test=0.811) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.805, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.808, test=0.803) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.805, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.807, test=0.803) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.742, test=0.738) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.751, test=0.757) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.729, test=0.729) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.808, test=0.803) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.805, test=0.811) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.807, test=0.803) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.749, test=0.755) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.802, test=0.798) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.801, test=0.796) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.738, test=0.734) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.726, test=0.726) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.801, test=0.805) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.738, test=0.734) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.749, test=0.755) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.726, test=0.726) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.802, test=0.798) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.801, test=0.805) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=7, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.801, test=0.796) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.788, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.844, test=0.840) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.788, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.764, test=0.763) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.844, test=0.840) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.774, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.788, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.844, test=0.840) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.774, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.788, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.764, test=0.763) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.788, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.788, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.764, test=0.763) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.844, test=0.840) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.844, test=0.840) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.844, test=0.840) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.764, test=0.763) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.764, test=0.763) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.764, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.774, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.787, test=0.777) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.774, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.787, test=0.777) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.764, test=0.763) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.764, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.764, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.764, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.764, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.3s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.841, test=0.838) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.841, test=0.838) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.841, test=0.838) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.843, test=0.837) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.843, test=0.837) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.843, test=0.837) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.841, test=0.838) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.774, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.3s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.774, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.843, test=0.837) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.844, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.841, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.844, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.843, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.843, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.843, test=0.839) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.773, test=0.762) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.763, test=0.762) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.787, test=0.778) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.840, test=0.838) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.842, test=0.836) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.840, test=0.838) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.773, test=0.762) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.787, test=0.778) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.763, test=0.762) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.840, test=0.838) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.843, test=0.839) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.842, test=0.836) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.755, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.738, test=0.739) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.748, test=0.748) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.755, test=0.746) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.738, test=0.739) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.748, test=0.748) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=8, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.797, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=3;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.797, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=4;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.797, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.805, test=0.797) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.892, test=0.890) total time=   0.3s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=5;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.797, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=6;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=7;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.797, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=8;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=9;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=2;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=3;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=5;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=6;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=7;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=8;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=9;, score=(train=0.894, test=0.887) total time=   0.3s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.797, test=0.787) total time=   0.3s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.892, test=0.890) total time=   0.3s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.892, test=0.891) total time=   0.3s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=2;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=3;, score=(train=0.894, test=0.887) total time=   0.3s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.797, test=0.787) total time=   0.3s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.800, test=0.795) total time=   0.3s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.797, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=5;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=6;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.797, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=7;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=9;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.805, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=3;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=4;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=5;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=6;, score=(train=0.894, test=0.887) total time=   0.3s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=7;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.892, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=8;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.800, test=0.795) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.892, test=0.892) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=9;, score=(train=0.894, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=3;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=4;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=5;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=6;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=7;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=8;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.796, test=0.788) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.805, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.892, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=9;, score=(train=0.893, test=0.887) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=2;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=3;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=4;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=5;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=6;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=7;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=8;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.804, test=0.796) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.800, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=9;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=2;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=3;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=4;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=5;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=6;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.891, test=0.890) total time=   0.3s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=7;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=8;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.796, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.891, test=0.890) total time=   0.3s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.891, test=0.891) total time=   0.3s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=7, min_samples_split=9;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=2;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=3;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=4;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.795, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=5;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=6;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.795, test=0.787) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=7;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=8;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.891, test=0.891) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=8, min_samples_split=9;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.890, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=2;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.891, test=0.889) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.890, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=3;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.891, test=0.889) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.890, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=4;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.891, test=0.889) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.890, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=5;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.795, test=0.786) total time=   0.3s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.890, test=0.890) total time=   0.3s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=6;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.891, test=0.890) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.890, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=7;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.891, test=0.889) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.890, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=8;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.795, test=0.786) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.804, test=0.795) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.799, test=0.794) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.891, test=0.889) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.890, test=0.890) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=None, min_samples_leaf=9, min_samples_split=9;, score=(train=0.893, test=0.886) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=2, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=4, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=6, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=8, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=2;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=3;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=4;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=5;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=6;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=7;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.665, test=0.667) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.670, test=0.675) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.665, test=0.668) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.667, test=0.659) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=9;, score=(train=0.666, test=0.664) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=1, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=2, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=3, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=4, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=5, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=6, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=7, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=8, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.701, test=0.705) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.697, test=0.685) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=2;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.696, test=0.692) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=3;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=4;, score=(train=0.689, test=0.691) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=5;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=6;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=7;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=8;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.690) total time=   0.1s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.701, test=0.705) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.689) total time=   0.1s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.697, test=0.685) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.696, test=0.692) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=16, min_samples_leaf=9, min_samples_split=9;, score=(train=0.689, test=0.691) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=1, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=2, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=3, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=4, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=5, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=6, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=7, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.1s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=8, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=2;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.741, test=0.741) total time=   0.2s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=3;, score=(train=0.798, test=0.795) total time=   0.2s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=4;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=5;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=6;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.797, test=0.805) total time=   0.1s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=7;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=8;, score=(train=0.798, test=0.795) total time=   0.1s\n",
            "[CV 1/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.756, test=0.746) total time=   0.2s\n",
            "[CV 2/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.741, test=0.741) total time=   0.1s\n",
            "[CV 3/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.760, test=0.756) total time=   0.2s\n",
            "[CV 4/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.797, test=0.805) total time=   0.2s\n",
            "[CV 5/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.804, test=0.801) total time=   0.2s\n",
            "[CV 6/6] END criterion=log_loss, max_depth=9, max_leaf_nodes=32, min_samples_leaf=9, min_samples_split=9;, score=(train=0.798, test=0.795) total time=   0.1s\n"
          ]
        }
      ],
      "source": [
        "dt_grid = GridSearchCV(dt_model, param_grid_2, cv=6, scoring=\"accuracy\", return_train_score=True, verbose=4)\n",
        "start = time.time()\n",
        "dt_grid.fit(X_train, y_train)\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OYY5Cu990Pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7e37c3-b36a-425b-b9f5-f0e7040a2dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9961314356528007\n",
            "{'criterion': 'log_loss', 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "DecisionTreeClassifier(criterion='log_loss', min_samples_split=3)\n",
            "5449.110018014908\n"
          ]
        }
      ],
      "source": [
        "print(dt_grid.best_score_)\n",
        "print(dt_grid.best_params_)\n",
        "print(dt_grid.best_estimator_)\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_HJgnHM90Pw"
      },
      "outputs": [],
      "source": [
        "y_pred = dt_grid.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZGbuZeq90Pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06c86f9-a996-4bdc-c31e-ca7b2a5e659e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree's accuracy:  0.996643196332078\n",
            "Decision Tree's precision:  0.9965054257862792\n",
            "Decision Tree's recall:  0.9959558823529412\n",
            "Decision Tree's F1 score:  0.9962305782844534\n"
          ]
        }
      ],
      "source": [
        "print(\"Decision Tree's accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"Decision Tree's precision: \", precision_score(y_test, y_pred))\n",
        "print(\"Decision Tree's recall: \", recall_score(y_test, y_pred))\n",
        "print(\"Decision Tree's F1 score: \", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A28meuD590Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf64b5d3-1792-4563-9270-f9eb87bcb7c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree's scores after tuning\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.997     0.997     0.997      6777\n",
            "           1      0.996     0.997     0.996      5437\n",
            "\n",
            "    accuracy                          0.997     12214\n",
            "   macro avg      0.997     0.997     0.997     12214\n",
            "weighted avg      0.997     0.997     0.997     12214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Decision Tree's scores after tuning\\n\", classification_report(y_pred, y_test, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RANDOM FOREST**"
      ],
      "metadata": {
        "id": "eLSZnEflApNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e83666a",
        "outputId": "c13f07f0-2f96-470e-dfae-2772932eaee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6700    1]\n",
            " [   0 5513]]\n",
            "Accuracy score using Random Forest is: 0.9999181267398067\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6700\n",
            "           1       1.00      1.00      1.00      5514\n",
            "\n",
            "    accuracy                           1.00     12214\n",
            "   macro avg       1.00      1.00      1.00     12214\n",
            "weighted avg       1.00      1.00      1.00     12214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "y_pred = rfc.predict(X_test)\n",
        "print(confusion_matrix(y_pred,y_test))\n",
        "print(f\"Accuracy score using Random Forest is: {accuracy_score(y_test,y_pred)}\")\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53b40656"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "rfc = RandomForestClassifier()\n",
        "operations = [('scaler', scaler), ('rfc', rfc)]\n",
        "pipe = Pipeline(operations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c0349d7"
      },
      "outputs": [],
      "source": [
        "min_samples_split = [3,5,7,9,11,15]\n",
        "n_estimators = [20,50,100,150,200,300]\n",
        "max_depth = [None, 5, 10]\n",
        "param_grid = {'rfc__min_samples_split':min_samples_split,\n",
        "              'rfc__n_estimators':n_estimators,\n",
        "              'rfc__max_depth' : max_depth}\n",
        "grid  = GridSearchCV(pipe,param_grid,cv =5, scoring ='accuracy',return_train_score =True,verbose =2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "4987378e",
        "outputId": "f420e822-50df-4b6a-e883-65e92e76dcc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   6.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   9.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   9.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   9.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   2.9s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   6.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   6.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   9.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   9.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   9.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.8s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   6.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   6.3s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   6.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   9.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   9.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   9.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   9.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   4.9s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   6.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   9.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   9.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   9.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   9.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.8s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.8s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.8s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   6.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   9.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   9.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   9.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   9.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   9.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   3.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   3.0s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   3.1s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   4.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   4.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   4.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   4.5s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   6.2s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   6.3s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   9.7s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   9.6s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=None, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   9.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   2.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   3.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   2.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   4.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   4.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   4.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   4.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   0.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   0.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   3.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   2.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   4.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   4.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   0.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   1.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   2.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   2.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   3.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   2.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   4.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   4.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   4.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   1.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   2.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   2.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   2.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   3.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   4.8s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   4.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   5.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   0.8s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   0.8s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   1.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   1.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   1.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   1.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   1.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   3.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   3.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   3.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   3.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   4.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   4.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   4.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   4.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   4.8s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   0.8s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   0.7s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   1.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   1.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   1.5s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   1.6s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   2.3s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   2.4s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   3.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   3.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   3.1s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   3.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   3.2s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   4.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   4.8s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   4.9s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   5.0s\n",
            "[CV] END rfc__max_depth=5, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   4.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   2.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   2.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   4.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   3.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   3.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   5.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=200; total time=   5.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   8.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   8.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   8.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   7.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=3, rfc__n_estimators=300; total time=   8.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=50; total time=   1.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=150; total time=   4.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   5.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   5.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=200; total time=   5.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   8.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   8.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   7.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   7.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=5, rfc__n_estimators=300; total time=   8.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   2.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=100; total time=   2.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   5.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   5.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=200; total time=   5.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   8.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   8.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   8.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   7.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=7, rfc__n_estimators=300; total time=   7.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   3.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=150; total time=   3.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   5.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   5.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   5.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   8.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   7.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   8.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   7.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=9, rfc__n_estimators=300; total time=   7.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   2.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   2.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   5.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   5.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   5.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=200; total time=   4.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   7.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   7.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   7.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   8.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=11, rfc__n_estimators=300; total time=   7.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=20; total time=   0.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=50; total time=   1.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   2.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   2.3s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   2.4s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   2.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=100; total time=   2.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   3.9s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   4.0s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   3.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=150; total time=   3.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   5.2s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   5.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   5.7s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   5.5s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=200; total time=   5.1s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   7.6s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   7.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   7.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   7.8s\n",
            "[CV] END rfc__max_depth=10, rfc__min_samples_split=15, rfc__n_estimators=300; total time=   7.6s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;rfc&#x27;, RandomForestClassifier())]),\n",
              "             param_grid={&#x27;rfc__max_depth&#x27;: [None, 5, 10],\n",
              "                         &#x27;rfc__min_samples_split&#x27;: [3, 5, 7, 9, 11, 15],\n",
              "                         &#x27;rfc__n_estimators&#x27;: [20, 50, 100, 150, 200, 300]},\n",
              "             return_train_score=True, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;rfc&#x27;, RandomForestClassifier())]),\n",
              "             param_grid={&#x27;rfc__max_depth&#x27;: [None, 5, 10],\n",
              "                         &#x27;rfc__min_samples_split&#x27;: [3, 5, 7, 9, 11, 15],\n",
              "                         &#x27;rfc__n_estimators&#x27;: [20, 50, 100, 150, 200, 300]},\n",
              "             return_train_score=True, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;rfc&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                       ('rfc', RandomForestClassifier())]),\n",
              "             param_grid={'rfc__max_depth': [None, 5, 10],\n",
              "                         'rfc__min_samples_split': [3, 5, 7, 9, 11, 15],\n",
              "                         'rfc__n_estimators': [20, 50, 100, 150, 200, 300]},\n",
              "             return_train_score=True, scoring='accuracy', verbose=2)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b405c82e",
        "outputId": "9f8417d3-774e-436b-c726-f9c5aa34bd6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;rfc&#x27;, RandomForestClassifier(min_samples_split=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;rfc&#x27;, RandomForestClassifier(min_samples_split=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=3)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('rfc', RandomForestClassifier(min_samples_split=3))])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57e965ad"
      },
      "outputs": [],
      "source": [
        "model_rfc = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d534025",
        "outputId": "d5724aaf-6948-49a1-82b2-f2d976fb804d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;rfc&#x27;, RandomForestClassifier(min_samples_split=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;rfc&#x27;, RandomForestClassifier(min_samples_split=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=3)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('rfc', RandomForestClassifier(min_samples_split=3))])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_rfc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba9bf8b1"
      },
      "outputs": [],
      "source": [
        "y_pred = model_rfc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75e2b584",
        "outputId": "53d43f3c-38cd-416b-8ce6-f9cbbbda372e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6700    2]\n",
            " [   0 5512]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_pred,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd91cda1",
        "outputId": "b680f81c-08a7-4c44-98e4-bb3f8309d162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score using Random Forest is: 0.9998362534796136\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6700\n",
            "           1       1.00      1.00      1.00      5514\n",
            "\n",
            "    accuracy                           1.00     12214\n",
            "   macro avg       1.00      1.00      1.00     12214\n",
            "weighted avg       1.00      1.00      1.00     12214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy score using Random Forest is: {accuracy_score(y_test,y_pred)}\")\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5572c39"
      },
      "outputs": [],
      "source": []
    }
  ]
}